{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Identification\n",
    "\n",
    "Identifying few strokes on a  piece of paper to be number may seem to be a piece of cake for us humans, thanks to millions of years of evolution and a highly evolved brain, but for a computer, this task can be really daunting. \n",
    "\n",
    "In this project, I trained a convolutional neural network to identify digits. Then I took it a step further by writing another program which can locate digits in a picture and then identify that them.\n",
    "\n",
    "![Image identifcation example](https://www.concordia.ca/students/birks/student-id/8-digit-student-id-card/_jcr_content/content-main/image.img.jpg/1449603985466.jpg)\n",
    "\n",
    "Follow this comprehensive notebook to gain a deeper understanding of the whole process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import model_from_json #Save neural network\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by disabling the warnings issued by Jupyter Notebook. They can tend to be irritating at times.\n",
    "\n",
    "We import __matplotlib__ for displaying the images in the notebook and _%matplotlib_ is a magic function in IPython which instructs the notebook to plot images right below the cell that produced it.\n",
    "\n",
    "We import the training data from Keras' dataset collection.\n",
    "\n",
    "An RGB image has three dimensions, namely - rows, columns and the number of colour channels which is three(Red, green and blue). So a 64x64 RGB image is represented as (64, 64, 3) by Keras.\n",
    "The __set_image_dim_ordering('th')__ function specifies if the colour channel comes first or last. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_data():\n",
    "    \n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    \n",
    "    train_data = train_data.reshape(train_data.shape[0], 1, 28, 28).astype('float32')/255\n",
    "    test_data = test_data.reshape(test_data.shape[0], 1, 28, 28).astype('float32')/255\n",
    "    \n",
    "    train_labels = np_utils.to_categorical(train_labels)\n",
    "    test_labels = np_utils.to_categorical(test_labels)\n",
    "    num_categories = test_labels.shape[1]\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels, num_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network requires a lot of data to train on and leaning on an existing dataset helps us save a lot of time. We will use the MNIST dataset of handwritten digits, which contains 70,000 images of digits that are  28 px wide and 28 px long.\n",
    "\n",
    "![MNIST sample image](https://corochann.com/wp-content/uploads/2017/02/mnist_plot.png)\n",
    "\n",
    "We load the required data into respective variables and then type-cast it and reshape the variables. Then normalise it by dividing it by 255. Rescaling the pixel values can speed up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_categories, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is invoked to build the neural network. Please refer to my previous notebook for explanations about each layer's functioning. Given bellow is a diagram of this CNN's architecture. \n",
    "![CNN Architecture](Cnn_architecture.jpg)\n",
    "\n",
    "We have two convolution layers that will scan the image part by part, to learn features associated with the certain digit. These layers are followed by a fully connected three-layered neural which aptly makes classifies the digit. We receive the output as probabilities and the digit with the highest probability is chosen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    path = \"Models\\\\\"\n",
    "    model_json = model.to_json()\n",
    "    with open(path + \"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(path + \"model_weights.h5\")\n",
    "    print(\"Neural Network saved to disk. Path:\",path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size =  60000\n",
      "Test data size =  10000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 30, 24, 24)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 10, 10)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 59,933\n",
      "Trainable params: 59,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.4104 - acc: 0.8711\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.1007 - acc: 0.9695\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0714 - acc: 0.9784\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0610 - acc: 0.9811\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0521 - acc: 0.9839\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0475 - acc: 0.9850\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0397 - acc: 0.9875\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0368 - acc: 0.9886\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0340 - acc: 0.9893\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0327 - acc: 0.9898\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0286 - acc: 0.9907\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0278 - acc: 0.9908\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0256 - acc: 0.9918\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0226 - acc: 0.9925\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0217 - acc: 0.9929\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0209 - acc: 0.9930\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0192 - acc: 0.9936\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0170 - acc: 0.9943\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0180 - acc: 0.9942\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0159 - acc: 0.9943\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0149 - acc: 0.9948\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0127 - acc: 0.9954\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0119 - acc: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x153024a5320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels, test_data, test_labels, num_categories = acquire_data()\n",
    "\n",
    "print (\"Train data size = \", len(train_data))\n",
    "print (\"Test data size = \", len(test_data))\n",
    "\n",
    "model = define_model()\n",
    "model.fit(train_data, train_labels, batch_size = 200, epochs = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  99.32 %\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(model.predict(test_data), axis = 1)\n",
    "test_labels = np.argmax(test_labels, axis = 1)\n",
    "print(\"Accuracy = \", accuracy_score(test_labels, predicted_labels)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved an accuracy of 99.32%. Well this is good but not too good. Higher accuracies can be achieved by using a different network or tuning the hyper-parameters(Number of Epochs, batch_size in this case). This model can now predict the digits accurately whenever it is tasked to do so. Though in real life numbers appear as a batch, what should we do in that case? Check the digit_locater_and_identifier.ipynb for the solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
